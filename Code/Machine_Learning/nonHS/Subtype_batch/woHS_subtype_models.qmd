---
title: "HS Subtype models"
author: "ThomThom"
format: html
editor: source
---

# Preparatory steps

Loading packages Store package names in a vectors for ease of access and to load them easily

```{r Setup, echo=FALSE, warning=FALSE}

# Define the vector of package names needed for the project
PACKAGES <- c(
  "xgboost",         # Extreme Gradient Boosting algorithm for classification/regression
  "ggplot2",         # Data visualization package based on the grammar of graphics
  "RColorBrewer",    # Color palettes for enhanced data visualization
  "tidymodels",      # Tidy modeling framework for machine learning workflows
  "tidyverse",       # Collection of packages for data manipulation, analysis, and visualization
  "finetune",        # Tools for model tuning and optimization
  "themis",          # Techniques for handling class imbalance in machine learning
  "gprofiler2",      # Gene enrichment and pathway analysis for gene lists
  "future",          # Enables parallel processing for faster computations
  "data.table",      # High-performance data manipulation package
  "gt",              # For creating display tables
  #"gtsummary",       # For summary tables with statistics and formatted output
  "butcher",         # Reduces memory load of models by removing unnecessary objects
  "UBL",              # Utility-based learning techniques for imbalanced data
  "ranger",
  "kernelshap",
  "shapviz"
)

# Use purrr::walk to load all packages
purrr::walk(PACKAGES, library, character.only = TRUE)
gc()

plan(multisession, workers = 10)
nbrOfWorkers()

RANDOM_SEED <- 1234
#plan("multisession", workers = 15,)
#plan(multisession, workers = 15)
#plan(sequential)


```

## Managing the data to use

```{r Data to use}
#| warning: false
# Load the data
# Read the CPM table, set the first column as row names, and transpose the data
ML_data <- fread("../../ALLDEGs/PCA_cpm_log_woHS_89_filtered.csv")
# Convert Ensembl IDs to gene names
gene_names <- gconvert(query = ML_data$V1, organism = "hsapiens", 
         target = "ENSG", mthreshold = Inf, filter_na = TRUE)
#ML_data$V1 == gene_names$target

ML_data$V1 <- gene_names$name

#ML_data$V1 <- gene_names$name
ML_data <- ML_data %>%
  tibble() %>%
  column_to_rownames(var = "V1") %>%  # Set first column as row names
  t() %>%  # Transpose the data for easier handling
  as_tibble(rownames = "sample")  # Convert to tibble and keep row names as a column

# Load validation data
ML_validation <- fread("../../ALLDEGs/cpm_table_log_30.csv") 
# Convert Ensembl IDs to gene names
gene_names <- gconvert(query = ML_validation$V1, organism = "hsapiens", 
         target = "ENSG", mthreshold = Inf, filter_na = TRUE)

ML_validation$V1 <- gene_names$name

ML_validation <- ML_validation %>%
  tibble() %>%
  distinct(V1, .keep_all = TRUE) %>%
  column_to_rownames(var = "V1") %>%  # Set first column as row names
  t() %>%  # Transpose the data for easier handling
  as_tibble(rownames = "sample")  # Convert to tibble and keep row names as a column

# Load metadata for sample subtypes
# Read the metadata file and rename the sample column for consistency
samples_70_explained <- read_csv("../../ALLDEGs/info_samples_70.csv") %>%
  tibble() %>%
  select(-...1) 

samples_30_explained <- read_csv("../../ALLDEGs/info_samples_30.csv") |>
  tibble() |>
  select(-...1)

# Merge and filter the data 70
ML_data <- ML_data %>%
  left_join(samples_70_explained, by = "sample") %>%  # Join tumor/control info
  filter(condition != "H") %>%  # Filter out samples with condition 'H'
  select(-c(type, age, replicate, condition))  # Remove unnecessary columns

# Convert to data frame and set sample as row names
ML_data <- data.frame(ML_data)  # Convert tibble to data frame
rownames(ML_data) <- ML_data$sample  # Set row names to 'sample'
ML_data$sample <- NULL  # Remove the sample column

# Merge and filter the data 30
ML_validation <- ML_validation %>%
  left_join(samples_30_explained, by = "sample") %>%  # Join tumor/control info
  filter(condition != "H") %>%  # Filter out samples with condition 'H'
  select(-c(type, age, replicate, condition))  # Remove unnecessary columns

# Convert to data frame and set sample as row names
ML_validation <- data.frame(ML_validation)  # Convert tibble to data frame
rownames(ML_validation) <- ML_validation$sample  # Set row names to 'sample'
ML_validation$sample <- NULL  # Remove the sample column

# Identify indices of samples with 'Unknown' cell types
unknown_indices <- which(ML_data$Cell_type == 'Unknown')  # Find 'Unknown' cell type indices
table(ML_data$Cell_type)  # Display counts of each cell type

#fake_data <- read_csv("output/tables/fake_data_FM_downsampled.csv") |>  filter(Cell_type != "PreB")
#fake_data <- read_csv("output/tables/fake_data.csv") |>  filter(Cell_type != "PreB")
#colnames(fake_data) <- colnames(ML_data)
#ML_data <- rbind(ML_data, fake_data)

# Clean up unnecessary variables to free memory
#rm(info_samples_Tumor_Control, samples_subtypes_explained)  # Remove temporary metadata


```

## Number coating

```{r Current otimal way  }
# Number encoding of categorical values
# Specify the columns to be label encoded
columns_to_encode <- c("Cell_type")

# Create separate datasets based on 'Cell_type'
# Create a new data frame without rows where 'Cell_type' is "Unknown"
my_data_train <- subset(ML_data, Cell_type != "Unknown")
# Create a separate dataset for rows where 'Cell_type' is "Unknown"
Unknown_data <- subset(ML_data, Cell_type == "Unknown")

# Convert specified columns to factor type
my_data_train <- my_data_train %>%
  mutate_at(columns_to_encode, as.factor)  # Convert 'type' to factor
Unknown_data <- Unknown_data %>% 
  mutate_at(columns_to_encode, as.factor)  # Convert 'type' to factor in Unknown_data

# Get the levels from ML_data
common_levels <- levels(my_data_train$Cell_type)

# Set the levels
ML_validation$Cell_type <- factor(ML_validation$Cell_type, levels = common_levels)

## Optional: Convert factors to numeric (commented out)
# train_data_numeric <- my_data_train %>% mutate_at(columns_to_encode, as.numeric)  # Convert factors to numeric

# Create a dictionary-like structure to store the levels of categorical variables
## The order corresponds to the number (commented out)
# my_levels <- list(Cell_type = levels(my_data_train$Cell_type))  # Store levels of 'Cell_type'

# Clean up unnecessary variables to free memory
rm(columns_to_encode)  
```

## Split tidymodels

```{r Split tidymodels }

set.seed(RANDOM_SEED)

# === Train/Test Split ===
train_data <- my_data_train
test_data  <- ML_validation

cli::cli_h3("\n[INFO] Train ML data before NCL:\n")
print(table(train_data$Cell_type))


Classes <- list("B" = 8, "PreB" = 1, "PreT" = 4, "T" = 2)
# === Advanced Class Balancing using UBL ===
# Apply ADASYN oversampling
#train_data <- AdasynClassif(Cell_type ~ ., train_data, beta = 0.2,k = 5,baseClass = "PreB")
train_data <- SMOGNClassif(Cell_type ~ ., train_data, C.perc =  Classes,k = 5)
#train_data <- SmoteClassif(Cell_type ~ ., train_data, C.perc = list("B" = 8, "PreB" = 1, "PreT" = 4, "T" = 2),k = 5)
cli::cli_h3("\n[INFO] Train ML data after Adasyn:\n")
print(table(train_data$Cell_type))
train_data <- NCLClassif(Cell_type ~ ., train_data,k = 5) #,Cl = c("B", "PreT", "T"),
cli::cli_h3("\n[INFO] Train ML data after NCL:\n")
print(table(train_data$Cell_type))

#train_data <- train_data |> mutate(Weights = hardhat::importance_weights(as.integer(Cell_type)))

# Calculate class frequencies
class_counts <- table(train_data$Cell_type)
total_samples <- sum(class_counts)
num_classes <- length(class_counts)

# Compute weights inversely proportional to class frequencies
class_weights <- (total_samples / (num_classes * class_counts))^0.5
class_weights <- c(as.numeric(class_weights))
class_weights <- class_weights / mean(class_weights)
names(class_weights) <- names(class_counts)

print(round(class_weights, 3))
# Assign weights to each observation
train_data <- train_data %>%
  mutate(Weights = class_weights[as.character(Cell_type)])

train_data$Weights <- hardhat::new_importance_weights(c(train_data$Weights))


# === Preprocessing Recipe ===
recipe <- recipe(Cell_type ~ ., data = train_data) 

# === Recipe Prep and Bake ===
rec_prep   <- prep(recipe, training = train_data)
baked_data <- bake(rec_prep, new_data = NULL)

cli::cli_h3("\n[INFO] Baked (final) ML training data:\n")
print(table(baked_data$Cell_type))

# === Cross-validation Splits ===
v_folds <- vfold_cv(train_data, strata = Cell_type, v = 5, repeats = 3)
#nested_cv(data = train_data)

# === Evaluation Metrics ===
class_metrics <- metric_set(kap, mcc, bal_accuracy, f_meas, roc_auc, ppv)


```


# Random Forest:

```{r RF with cross validation from tidymodels}
set.seed(RANDOM_SEED)

# Step 1: Define RF specification with tunable hyperparameters
rf_spec <- 
  rand_forest(
    min_n = tune(),
    trees = tune(),
    mtry = tune()
  ) %>%
  set_mode("classification") %>%
  set_engine("ranger", importance = "permutation") |> #permutation
  translate()

# Step 2: Define full parameter search space
rf_param_space <- extract_parameter_set_dials(rf_spec) %>%
  finalize(train_data) %>%
  update(
    min_n = min_n(range = c(3L, 15L)),
    trees = trees(range = c(500L, 1500L)),
    mtry = mtry(range = c(5L, 89L)) # Adjust to your feature space
  )

# Step 3: Create initial space-filling grid
rf_grid <- grid_space_filling(rf_param_space, size = 25, type = "latin_hypercube")

# Step 4: Build tuning workflow
rf_workflow <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(rf_spec) |>
  add_case_weights(col = Weights)

# Step 5: Run tuning (grid → annealing → bayes)
rf_tune_grid <- tune_grid(
  rf_workflow,
  resamples = v_folds,
  grid = rf_grid,
  metrics = class_metrics
)

rf_tune_bayes <- tune_bayes(
  rf_workflow,
  resamples = v_folds,
  initial = rf_tune_grid,
  param_info = rf_param_space,
  iter = 30,
  metrics = class_metrics,
  control = control_bayes(no_improve = 10, verbose_iter = TRUE)
)

# Step 6: Inspect best MCC
show_best(rf_tune_bayes, metric = "mcc")

# Step 7: Select best by MCC or mcc
rf_best_params <- select_best(rf_tune_bayes, metric = "mcc")

# Step 8: Finalize and fit
final_rf_workflow <- finalize_workflow(rf_workflow, rf_best_params)

rf_fit <- fit(final_rf_workflow, data = train_data)

# Step 9: Print model and optionally butcher
print(rf_fit)
```

## Results RF

```{r Plots for RF}
# Set seed for reproducibility
set.seed(RANDOM_SEED)

# Fit the model to resamples (this is what stacks needs)
RF_res <- fit_resamples(
  final_rf_workflow,
  resamples = v_folds,
  metrics = class_metrics,
  control = control_resamples(save_pred = TRUE, save_workflow = TRUE)
)

collect_metrics(RF_res)

# Extract predictions from the trained random forest model
predictions <- rf_fit %>%
  predict(new_data = test_data) %>% # Generate predictions on the test data
  dplyr::mutate(Cell_type = test_data$Cell_type) # Add true cell type to predictions

# Create a confusion matrix to evaluate model performance
confusion <- conf_mat(predictions, truth = Cell_type, estimate = .pred_class)
metrics_df <- summary(confusion) # Summarize confusion matrix metrics
metrics_df # Display metrics

# Visualize confusion matrix as a heatmap
autoplot(confusion, type = "heatmap") +
  labs(title = "Confusion Matrix - RF HS Subtype Batch Heatmap")

write_csv(metrics_df, "output/tables/RF_tuned_metrics.csv")

```


# K-Nearest Neighbors (KNN) Model:

```{r KKNN with CV}
set.seed(RANDOM_SEED)

# Define KNN model spec with tuneable neighbors only
knn_spec <- nearest_neighbor(
  weight_func = "optimal",
  neighbors = tune()
) %>%
  set_mode("classification") %>%
  set_engine("kknn")

# HDLSS = High-Dimensional, Low Sample Size
# This dataset (n = 1000, p = 89) is HDLSS-adjacent — dimensionality is moderate, 
# so KNN may still be unstable for low k

# Define and finalize the KNN hyperparameter space for this setting
knn_param_space <- extract_parameter_set_dials(knn_spec) %>%
  finalize(train_data) |>
  update(
    # Set a safe and empirically justified neighbor range
    # Avoid low k (e.g. 3 or 5), as it overfits in moderate/high-dimensional data
    # Start tuning from k = 7 (min stability threshold) to √n ≈ 31 (smoothed upper bound)
    neighbors = neighbors(c(7L, 31L))
  )


# Generate a smaller, efficient Latin hypercube grid for tuning
knn_grid <- grid_space_filling(knn_param_space, size = 25, type = "latin_hypercube")

# Build the workflow
knn_workflow <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(knn_spec)

# Step 1: Tune with grid search
knn_tune_grid <- tune_grid(
  knn_workflow,
  resamples = v_folds,
  grid = knn_grid,
  metrics = class_metrics,
  control = control_grid(save_pred = TRUE,verbose = T)
)

# Show top tuning results by MCC
best_knn_results <- show_best(knn_tune_grid, metric = "mcc")
print(best_knn_results)

# Select best hyperparameters
best_knn_params <- select_best(knn_tune_grid, metric = "mcc")

# Finalize workflow with best params and fit on full training data
final_knn_workflow <- finalize_workflow(knn_workflow, best_knn_params)

knn_fit <- fit(final_knn_workflow, data = train_data)

print(knn_fit)


# Save lighter model
#cleaned_KNN <- butcher(Knn_fit, verbose = TRUE)

```

## Results KNN

```{r plots for KKNN}
set.seed(RANDOM_SEED)

knn_res <- fit_resamples(
  final_knn_workflow,
  resamples = v_folds,
  metrics = class_metrics,
  control = control_resamples(save_pred = TRUE, save_workflow = TRUE)
)

collect_metrics(knn_res)

# Extract predictions
predictions <- knn_fit %>%
  predict(new_data = test_data) %>%
  mutate(Cell_type = test_data$Cell_type)

# Create a confusion matrix
confusion <- conf_mat(predictions,truth = Cell_type, estimate = .pred_class)
metrics_df <- summary(confusion)
metrics_df

# View the confusion matrix
autoplot(confusion, type = "heatmap") +
  labs(title = "Confusion Matrix - KNN(8) HS Subtype Batch Heatmap ")

#write_csv(metrics_df, "KNN_tuned_metrics.csv")

```

# XGBoost (Extreme Gradient Boosting):

```{r Use xgb with CV}
library(tidymodels)
library(xgboost)
set.seed(RANDOM_SEED)

#--- XGBoost Spec with Regularization and Tweaked Defaults ---
xgb_spec <- boost_tree(
  trees = tune(),
  tree_depth = tune(),
  learn_rate = tune(),
  mtry = tune(),
  min_n = tune(),
  stop_iter = 10                 # for early stopping
) %>% 
  #set_engine("xgboost", objective = "multi:softprob") |>
  set_engine("xgboost", objective = "multi:softprob") |>
  set_mode("classification" ) 

#--- Tunable Parameters ---
xgb_param_space <- extract_parameter_set_dials(xgb_spec) %>%
  update(
    trees = trees(c(500L, 1500L)),
    tree_depth = tree_depth(c(3L, 10L)),
    learn_rate = learn_rate(c(0.01, 0.3)),  # fine-grained learning rate
    mtry = mtry(c(5L, 89L)),
    min_n = min_n(c(2L, 20L))
  )

#--- Grid Definition ---
xgb_grid <- grid_space_filling(
  xgb_param_space,
  size = 25,
  type = "latin_hypercube"
)

#--- Workflow Setup ---
xgb_workflow <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(xgb_spec) %>%
  add_case_weights(Weights)

#--- Grid Search (Initial) ---
xgb_tune_grid <- tune_grid(
  xgb_workflow,
  resamples = v_folds,
  grid = xgb_grid,
  metrics = class_metrics,
  control = control_grid(save_pred = TRUE)
)

#--- Bayesian Tuning (Refinement) ---
xgb_tune_bayes <- tune_bayes(
  xgb_workflow,
  resamples = v_folds,
  initial = xgb_tune_grid,
  param_info = xgb_param_space,
  iter = 30,
  metrics = class_metrics,
  control = control_bayes(
    no_improve = 10,
    verbose_iter = T,
    save_pred = TRUE,
    save_workflow = TRUE
  )
)

#--- Final Selection ---
xgb_best_params <- select_best(xgb_tune_bayes, metric = "mcc") #mcc

#--- Final Workflow ---
xgb_final_wf <- finalize_workflow(xgb_workflow, xgb_best_params)

#--- Final Fit on Training Data ---
xgb_fit <- fit(xgb_final_wf, data = train_data)

#--- Evaluate ---
collect_metrics(xgb_tune_bayes) %>% arrange(desc(mean))

# Save lighter model
#cleaned_XGB <- butcher(xgb_fit, verbose = TRUE)

```

## Results XGBoost

```{r plot xgb }
set.seed

# Fit the model to resamples (this is what stacks needs)
XGB_res <- fit_resamples(
  xgb_final_wf,
  resamples = v_folds,
  metrics = class_metrics,
  control = control_resamples(save_pred = TRUE, save_workflow = TRUE)
)

collect_metrics(XGB_res)

# Extract predictions
predictions <- xgb_fit %>%
  predict(new_data = test_data) %>%
  mutate(Cell_type = test_data$Cell_type)

# Create a confusion matrix
confusion <- conf_mat(predictions,truth = Cell_type, estimate = .pred_class)
metrics_df <- summary(confusion)
metrics_df

# Visualize confusion matrix as a heatmap
autoplot(confusion, type = "heatmap") +
  labs(title = "Confusion Matrix - XGB HS Subtype Batch Heatmap")

#write_csv(metrics_df,"XGB_tuned_metrics.csv")


```

# SVM
## SVM RBF

```{r}
set.seed(RANDOM_SEED)
#class_metrics <- metric_set(bal_accuracy,mcc, accuracy, f_meas, kap, roc_auc)
# Define the model specification with SVM and RBF kernel
svm_spec <- svm_rbf(
  cost = tune(),       # Cost parameter (C)
  rbf_sigma = tune(),   # Sigma parameter for RBF kernel
  margin = tune()
) %>%
  set_mode("classification") %>%
  set_engine("kernlab")

svm_grid <- extract_parameter_set_dials(svm_spec) %>%
  finalize(train_data |> select(-Cell_type)) %>%
  grid_space_filling(size = 25, type = "latin_hypercube")

# Create the workflow
svm_workflow <- 
  workflow() %>%
  add_recipe(recipe) %>%
  add_model(svm_spec)

# Perform initial grid tuning
tune_grid_results <- tune_grid(
  svm_workflow,
  resamples = v_folds, 
  grid = svm_grid,
  metrics = class_metrics,
  control = control_grid(save_pred = TRUE)
)

# Bayesian optimization tuning to refine the search
tune_bayes_results <- tune_bayes(
  svm_workflow,
  resamples = v_folds,
  iter = 25,              # Number of Bayesian iterations
  initial = tune_grid_results,
  metrics = class_metrics,
  control = control_bayes(no_improve = 5, verbose_iter = T)
)

# Create tuning visualization
autoplot(tune_bayes_results) +
  theme_minimal() +
  labs(title = "SVM with RBF Kernel - Hyperparameter Tuning Results")

# Select the best hyperparameters
best_params <- select_best(tune_bayes_results, metric = "mcc") # "mcc" "bal_accuracy"
print(best_params)

# Finalize the workflow with the best parameters
final_svm_rbf_workflow <- finalize_workflow(svm_workflow, best_params)

# Fit the model on training data
svm_rbf_fit <- final_svm_rbf_workflow %>%
  fit(data = train_data)

# Print summary of the fitted workflow
print(svm_rbf_fit)

# Save lighter model using butcher
#cleaned_svm_rbf <- butcher(svm_rbf_fit, verbose = TRUE)

```


### Metrics
```{r}
set.seed(RANDOM_SEED)

# Fit the model to resamples (this is what stacks needs)
SVM_rbf_res <- fit_resamples(
  final_svm_rbf_workflow,
  resamples = v_folds,
  metrics = class_metrics,
  control = control_resamples(save_pred = TRUE, save_workflow = TRUE)
)

collect_metrics(SVM_rbf_res)

# Extract predictions from test data
predictions <- svm_rbf_fit %>%
  predict(new_data = test_data) %>%
  mutate(Cell_type = test_data$Cell_type)

# Create a confusion matrix
confusion <- conf_mat(predictions, truth = Cell_type, estimate = .pred_class)
print(confusion)

# Get detailed metrics
metrics_df <- summary(confusion)
print(metrics_df)

# Visualize confusion matrix
autoplot(confusion, type = "heatmap") +
  #theme_void() +
  labs(title = "Confusion Matrix - SVM-RBF Subtype Batch Heatmap")

# Save metrics to CSV
#write_csv(metrics_df, "SVM_RBF_tuned_metrics.csv")

```

## SVM linear

```{r}
set.seed(RANDOM_SEED)

# Define the model specification with SVM Linear kernel
svm_linear_spec <- svm_linear(
  cost = tune(),       # Cost parameter (C)
  margin = tune()      # Margin parameter
) %>%
  set_mode("classification") %>%
  set_engine("kernlab")

# Use the Latin hypercube sampling approach you preferred
svm_grid <- extract_parameter_set_dials(svm_linear_spec) %>%
  finalize(train_data |> select(-Cell_type)) %>%
  grid_space_filling(size = 25, type = "latin_hypercube")

# Create the workflow
svm_workflow <- 
  workflow() %>%
  add_recipe(recipe) %>%
  add_model(svm_linear_spec) 

# Perform initial grid tuning
tune_grid_results <- tune_grid(
  svm_workflow,
  resamples = v_folds, 
  grid = svm_grid,
  metrics = class_metrics,
  control = control_grid(save_pred = TRUE)
)

# Show initial results
initial_results <- show_best(tune_grid_results, metric = "mcc", n = 5)
print(initial_results)

# Bayesian optimization tuning to refine the search
tune_bayes_results <- tune_bayes(
  svm_workflow,
  resamples = v_folds,
  iter = 25,              # Number of Bayesian iterations
  initial = tune_grid_results,
  metrics = class_metrics,
  control = control_bayes(no_improve = 5, verbose_iter = T)
)

# Collect and display final tuning results
tuning_results <- show_best(tune_bayes_results, metric = "mcc")
print(tuning_results)

# Create tuning visualization
autoplot(tune_bayes_results) +
  theme_minimal() +
  labs(title = "SVM with Linear Kernel - Hyperparameter Tuning Results")

# Select the best hyperparameters
best_params <- select_best(tune_bayes_results, metric = "mcc") # bal_accuracy mcc
print(best_params)

# Finalize the workflow with the best parameters
final_svm_linear_workflow <- finalize_workflow(svm_workflow, best_params)

# Fit the model on training data
svm_linear_fit <- final_svm_linear_workflow %>%
  fit(data = train_data)

# Print summary of the fitted workflow
print(svm_linear_fit)

# Save lighter model using butcher
#cleaned_svm_linear <- butcher(svm_linear_fit, verbose = TRUE) 

```


### Metrics
```{r}
# Extract predictions from test data
predictions <- svm_linear_fit %>%
  predict(new_data = test_data) %>%
  mutate(Cell_type = test_data$Cell_type)

# Create a confusion matrix
confusion <- conf_mat(predictions, truth = Cell_type, estimate = .pred_class)
print(confusion)

# Get detailed metrics
metrics_df <- summary(confusion)
print(metrics_df)

# Visualize confusion matrix
autoplot(confusion, type = "heatmap") +
  labs(title = "Confusion Matrix - SVM-Linear Subtype Batch Heatmap")

# Save metrics to CSV
write_csv(metrics_df, "output/tables/SVM_Linear_tuned_metrics.csv")

# Fit the model to resamples (this is what stacks needs)
SVM_linear_res <- fit_resamples(
  final_svm_linear_workflow,
  resamples = v_folds,
  metrics = class_metrics,
  control = control_resamples(save_pred = TRUE, save_workflow = TRUE)
)

collect_metrics(SVM_linear_res)

```

# LASSO

```{r}

set.seed(RANDOM_SEED)

# Define the model specification with LASSO
lasso_spec <- multinom_reg(
  penalty = tune(),      # Regularization parameter
  mixture = 1          # 1 = LASSO, 0 = Ridge, values between = Elastic Net
) %>%
  set_mode("classification") %>%
  set_engine("glmnet")

# Use the Latin hypercube sampling approach for the penalty parameter
lasso_grid <- extract_parameter_set_dials(lasso_spec) %>%
  finalize(train_data) %>%  # Uncomment if needed for specific values
  grid_space_filling(size = 25, type = "latin_hypercube")

# Create the workflow
lasso_workflow <- 
  workflow() %>%
  add_recipe(recipe) %>%
  add_model(lasso_spec) |>   add_case_weights(col = Weights)

# Perform initial grid tuning
tune_grid_results <- tune_grid(
  lasso_workflow,
  resamples = v_folds, 
  grid = lasso_grid,
  metrics = class_metrics,
  control = control_grid(save_pred = TRUE)
)

# Show initial results
initial_results <- show_best(tune_grid_results, metric = "mcc", n = 5)
print(initial_results)

# Bayesian optimization tuning to refine the search
tune_bayes_results <- tune_bayes(
  lasso_workflow,
  resamples = v_folds,
  iter = 25,              # Number of Bayesian iterations
  initial = tune_grid_results,
  metrics = class_metrics,
  control = control_bayes(no_improve = 5, verbose_iter = T)
)

# Collect and display final tuning results
tuning_results <- show_best(tune_bayes_results, metric = "mcc", n = 10)
print(tuning_results)

# Create tuning visualization
autoplot(tune_bayes_results) +
  theme_minimal() +
  labs(title = "LASSO Model - Hyperparameter Tuning Results")

# Select the best hyperparameters
best_params <- select_best(tune_bayes_results, metric = "mcc")
print(best_params)

# Finalize the workflow with the best parameters
final_lasso_workflow <- finalize_workflow(lasso_workflow, best_params)

# Fit the model on training data
lasso_fit <- final_lasso_workflow %>%
  fit(data = train_data)

# Print summary of the fitted workflow
print(lasso_fit)

# Save lighter model using butcher
cleaned_lasso <- butcher(lasso_fit, verbose = TRUE) 

```


## Metrics
```{r}

# Extract predictions from test data
predictions <- lasso_fit %>%
  predict(new_data = test_data) %>%
  mutate(Cell_type = test_data$Cell_type)

# Create a confusion matrix
confusion <- conf_mat(predictions, truth = Cell_type, estimate = .pred_class)
print(confusion)

# Get detailed metrics
metrics_df <- summary(confusion)
print(metrics_df)

# Visualize confusion matrix
autoplot(confusion, type = "heatmap") +
  labs(title = "Confusion Matrix - LASSO Subtype Batch Heatmap")

# Save metrics to CSV
write_csv(metrics_df, "output/tables/LASSO_tuned_metrics.csv")

# Fit the model to resamples (this is what stacks needs)
LASSO_res <- fit_resamples(
  final_lasso_workflow,
  resamples = v_folds,
  metrics = class_metrics,
  control = control_resamples(save_pred = TRUE, save_workflow = TRUE)
)

```


# STACK models
```{r}
# Now you can use this for stacking
# First, load the stacks library if not already loaded
set.seed(RANDOM_SEED)
library(stacks)

# Initialize a model stack
model_stack <- stacks() %>%
  add_candidates(LASSO_res) %>%
  add_candidates(SVM_linear_res) %>%
  add_candidates(SVM_rbf_res) %>%
  add_candidates(RF_res) %>%
  add_candidates(XGB_res) %>%
  blend_predictions(
    metric = metric_set(kap),
    times = 300,                    # Increase for stability
    control = control_grid(
      verbose = TRUE,
      save_pred = TRUE          
    )
  ) %>%
  fit_members()

#saveRDS(object = model_stack,file = "model_stack.RDS")
print(model_stack)
# Visualize the model weights
autoplot(model_stack, type = "performance")
autoplot(model_stack, type = "weights")
autoplot(model_stack, type = "members")

# Now you can make predictions with the stack on new data
stack_preds <- model_stack %>%
  predict(new_data = test_data) %>%
  mutate(Cell_type = test_data$Cell_type)

# Evaluate stack performance
stack_confusion <- conf_mat(stack_preds, truth = Cell_type, estimate = .pred_class)
stack_metrics <- summary(stack_confusion)
stack_metrics

# Visualize confusion matrix for the stacked model
autoplot(stack_confusion, type = "heatmap") +
  labs(title = "Confusion Matrix - Stacked Model for HS Subtype Classification")

# Save metrics
#write_csv(stack_metrics, "stacked_model_metrics.csv")
#Cleaned_stack <- butcher(model_stack,verbose = T)

```


# Dotplot metrics

```{r prepare_metrics}
library(tidyverse)

# Define a function to process metrics files
process_metrics <- function(file, model_name) {
  read_csv(file) %>%
    select(-.estimator) %>%
    t() %>%
    as.data.frame() %>%
    `rownames<-`(NULL) %>%
    setNames(.[1, ]) %>%
    slice(-1) %>%
    mutate(Model = model_name) %>%
    as_tibble()
}

# List of all metrics files and their corresponding model names
metrics_files <- list(
  "output/tables/RF_tuned_metrics.csv" = "RF", #  Tailored_RF_metrics.csv
  #"output/tables/Mlp_tuned_metrics.csv" = "MLP",
  "output/tables/Tailored_KKNN_metrics.csv" = "KNN(7)",
  "output/tables/Tailored_XGB_metrics.csv" = "XGBoost",
  "output/tables/Tailored_SVMrbf_metrics.csv" = "SVM RBF",
  "output/tables/SVM_Linear_tuned_metrics.csv" = "SVM Linear",
  "output/tables/LASSO_tuned_metrics.csv" = "LASSO",
  "output/tables/Tailored_Stack_metrics.csv" = "STACKED (all models)"
)

# Process all files and combine
all_metrics <- map2_dfr(names(metrics_files), metrics_files, process_metrics) %>%
  mutate(across(c(bal_accuracy, kap, f_meas, mcc), as.numeric)) %>%
  select(-ppv) |>
  mutate(UN_mcc = (mcc + 1) / 2) |>
  select(Model, mcc, everything()) %>%
  arrange(desc(mcc)) %>%
  mutate(across(where(is.numeric), ~ signif(.x, 3)),
         data = "nonHS") 

all_metrics

# Save results
write_csv(all_metrics, "output/tables/Metrics_nonHS_Subtype.csv")

```

```{r}
library(ggsci)

# Your data wrangling
plot_data <- all_metrics %>%
  select(Model, f_meas, mcc, bal_accuracy) %>%
  mutate(Model = reorder(Model, mcc)) %>%  # Order by MCC
  pivot_longer(cols = c(f_meas, mcc, bal_accuracy),
               names_to = "Metric", values_to = "Value") %>%
  mutate(Label = sprintf("%.2f", Value)) %>%
  mutate(Metric = recode(Metric,
                         "f_meas" = "F1 Score",
                         "mcc" = "Matthews Correlation Coefficient",
                         "bal_accuracy" = "Balanced Accuracy"))

# Plot
HS_simple_bar <- ggplot(plot_data, aes(x = Model, y = Value, fill = Metric)) +
  geom_col(position = position_dodge(0.7), width = 0.6) +
  geom_text(aes(label = Label), position = position_dodge(0.7), vjust = -0.5, size = 4.5) +
  scale_fill_npg() +
  labs(title = "nonHS Subtype Models Performances", 
       y = "Score", 
       fill = "Metric") +
  theme_bw(base_size = 15) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        legend.position = "top") +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.2))

print(HS_simple_bar)

ggsave("woHS_simple_bar_Sub.png", plot = HS_simple_bar, width = 12, height = 8, dpi = 600, bg = "white")

```


## More plots
```{r prepare_metrics}

library(tidyverse)
library(ggrepel)
library(ggsci)

# Load, tag, and process HS data
Metrics_HS_Subtype <- vroom::vroom("F:/ML/HS/Subtype_batch/output/tables/Metrics_HS_Subtype.csv") %>%
  mutate(data = "HS")


Metrics_nonHS_Subtype <- vroom::vroom("output/tables/Metrics_nonHS_Subtype.csv") %>%
  mutate(data = "nonHS")


numeric_cols <- names(Metrics_HS_Subtype)[2:(ncol(Metrics_HS_Subtype) - 1)]

# Combine and clean datasets
mixed_metrics <- bind_rows(
  Metrics_nonHS_Subtype %>% mutate(across(all_of(numeric_cols), as.numeric)),
  Metrics_HS_Subtype %>% mutate(across(all_of(numeric_cols), as.numeric))
) %>%
  mutate(Model = str_replace(Model, "KNN\\(\\d\\)", "KNN"),
  data = factor(data, levels = c("nonHS","HS")))


```


```{r}

library(ggplot2)
library(ggrepel)
library(ggsci)
library(dplyr)

# Define consistent model palette
model_levels <- unique(mixed_metrics$Model)
model_levels
model_palette <- setNames(
  pal_npg("nrc")(length(model_levels)),
  model_levels
)

model_palette
# Prepare the data
plot_data_line <- mixed_metrics |>
  select(Model, mcc,f_meas,UN_mcc, data) |>
  mutate(
    mcc = as.numeric(mcc),
    Model = factor(Model, levels = model_levels),
    data = factor(data, levels = c("nonHS", "HS")),
    composite_score = (f_meas * UN_mcc)
  )

# Plot
lineplot <- ggplot(plot_data_line, aes(x = data, y = composite_score, group = Model, color = Model)) +
  geom_line(linewidth = 1) +
  geom_point(size = 3) +
geom_label_repel(
  data = ~filter(.x, data == "HS"),
  aes(label = Model),
  box.padding = 0.5,
  label.size = 0.25,
  size = 4,
  fontface = "bold",
  label.r = unit(0.15, "lines"),
  label.padding = unit(0.2, "lines"),
  segment.size = 0.1,
  nudge_x = 0.1,      # Push right beyond "HS"
  hjust = 0,          # Left-align text (anchor to start)
  direction = "y",    # Spread labels vertically
  show.legend = FALSE
) +
  scale_color_manual(values = model_palette) +
  scale_y_continuous(limits = c(0.3, 1), breaks = seq(0, 1, 0.05)) +
  scale_x_discrete(expand = expansion(mult = c(0.1, 0.5))) +
  labs(
    title = "Performance on subtype classification",
    x = "DEGs",
    y = "Performance"
  ) +
  theme_bw(base_size = 15) +
  theme(
    legend.position = "none",
    plot.title = element_text(hjust = 0.5, face = "bold", size = 20),
    axis.title = element_text(size = 16, face = "bold"),
    axis.text.x = element_text(size = 14, face = "bold"),
    axis.ticks.length = unit(-0.2, "cm"),
    panel.grid.major.y = element_line(color = "lightgray", linewidth = 0.2),
    panel.grid.minor.y = element_blank()
  )
lineplot

ggsave("output/figures/all_models_mcc_boxed_labels3.png", lineplot, width = 10, height = 6, dpi = 600, bg = "white")
library(svglite)

ggsave("output/figures/all_models_mcc_boxed_labels.svg", lineplot, device = svglite::svglite, width = 10, height = 6)




```


```{r}

library(patchwork)
library(svglite)

# Shared axis labels
comb_MCC <- (lineplot + lineplot_age + labs(y = NULL)) +
  plot_annotation(tag_levels = 'A') 
comb_MCC

# Save
ggsave("output/figures/comb_MCC.png", comb_MCC, width = 12, height = 6, dpi = 600, bg = "white")
ggsave("output/figures/comb_MCC.svg", comb_MCC, device = svglite::svglite, width = 12, height = 6)



```

# Utilities
## Calibration
```{r}

calibrate_and_save <- function(model, test_data, model_name,method) {
  library(tailor)
  library(probably)
  library(dplyr)
  library(readr)
  library(ggplot2)
  
  set.seed(RANDOM_SEED)
  
  # Predict class and probabilities
  class_preds <- predict(model, new_data = test_data, type = "class")
  prob_preds <- predict(model, new_data = test_data, type = "prob")
  
  # Combine predictions and true labels
  predictions <- bind_cols(class_preds, prob_preds) %>%
    mutate(truth = test_data$Cell_type) %>%
    rename(predicted = .pred_class)
  
  # Build and fit calibration model (e.g., isotonic)
  post_obj <- tailor() %>% adjust_probability_calibration(method = method)
  post_res <- fit(post_obj, predictions, outcome = truth, estimate = predicted, probabilities = starts_with(".pred_"))
  
  # Get calibrated probabilities
  calibrated_probs <- predict(post_res, predictions, type = "prob")
  
  # Confusion matrix and metrics summary
  confusion <- conf_mat(calibrated_probs, truth = truth, estimate = predicted)
  metrics_df <- summary(confusion)
  print(metrics_df)
  # Plot confusion heatmap
  print(autoplot(confusion, type = "heatmap"))
  
  # Save metrics and calibration model files
  write_csv(metrics_df, file = paste0("output/tables/Tailored_", model_name, "_metrics.csv"))
  saveRDS(post_res, file = paste0("output/objects/", model_name, "_tailor.RDS"))
  
  # Return metrics and calibration model object
  list(metrics = metrics_df, calibration_model = post_res)
}

# isotonic beta
XGB_results <- calibrate_and_save(xgb_fit, test_data, "XGB","isotonic")

RF_results <- calibrate_and_save(rf_fit, test_data, "RF","beta")
#results <- calibrate_and_save(xgb_fit, test_data, "XGB")

SVMrbf_results <- calibrate_and_save(svm_rbf_fit, test_data, "SVMrbf","isotonic")

SVMlinear_results <- calibrate_and_save(svm_linear_fit, test_data, "SVMlinear","isotonic")

LASSO_results <- calibrate_and_save(lasso_fit, test_data, "LASSO","isotonic")

KKNN_results <- calibrate_and_save(knn_fit, test_data, "KKNN","isotonic")

Stack_results <- calibrate_and_save(model_stack, test_data, "Stack","isotonic")

```

# SHAP 
## RF
```{r}
library(ranger)
set.seed(1)

x <- train_data[-ncol(train_data)]
stratified_subset <- train_data %>%
  initial_split(prop = 100 / nrow(train_data), strata = Cell_type) %>%
  training() |>
  select(-Cell_type)

# Step 1: Calculate Kernel SHAP values
library(doFuture)
registerDoFuture()
plan(multisession, workers = 15)
SHAP_kernel_RF <- kernelshap(extract_fit_engine(rf_fit), x, bg_X = stratified_subset) pred_fun

# Step 2: Turn them into a shapviz object
SHAP_viz_RF <- shapviz(SHAP_kernel_RF, interactions = TRUE)

# Save SHAP importance (beeswarm plot) as PNG with 600 DPI and a title
plot_beeswarm <- sv_importance(SHAP_viz_RF, show_numbers = TRUE, kind = "beeswarm") & theme_bw(base_size = 15)
plot_beeswarm
ggsave("SHAP/sv_importance_RF_Subtype_beeswarm.png", plot = plot_beeswarm, dpi = 600,width = 12,height = 8)

# Save SHAP importance (default plot) as PNG with 600 DPI
plot_default <- sv_importance(SHAP_viz_RF, show_numbers = TRUE,max_display = 15) +
  ggtitle("SHAP Importance RF Subtype") + theme_bw(base_size = 20)
plot_default
ggsave("SHAP/sv_importance_RF_Subtype_default.png", plot = plot_default, dpi = 600,width = 12,height = 8)

# Save SHAP dependence plot for 'EBF1' as PNG with 600 DPI
plot_dependence <- sv_dependence(SHAP_viz_RF, v = "EBF1", color_var = "auto") & theme_bw(base_size = 15) # & geom_smooth(method = lm)
plot_dependence
ggsave("SHAP/sv_dependence_RF_Subtype_EBF1.png", plot = plot_dependence, dpi = 600,width = 12,height = 8)

# Save SHAP waterfall plot as PNG with 600 DPI
plot_waterfall <- sv_waterfall(SHAP_viz_RF) +
  ggtitle("SHAP waterfall RF Subtype") & theme_bw(base_size = 15)
plot_waterfall
ggsave("SHAP/sv_waterfallRF_Subtype.png", plot = plot_waterfall, dpi = 600,width = 12,height = 8)

```

## XBGoost
```{r}
library(xgboost)
library(kernelshap)
library(shapviz)

# Extract fitted xgboost model
XGB <- extract_fit_engine(xgb_fit)

# Prepare predictor matrix (same as used in model fitting)
x <- baked_data
x$Cell_type <- as.numeric(x$Cell_type) - 1

# Stratified small subset for readable axis labels (optional)
stratified_subset <- x %>%
  initial_split(prop = 0.05, strata = Cell_type) %>%  # ~5% stratified sample
  training() %>%
  select(-Cell_type)

# Matrix input for SHAP prediction (must match training format)
X_pred <- data.matrix(x %>% select(-Cell_type))

# Run SHAP
SHAP_viz_XGB <- shapviz(XGB, X_pred = X_pred, X = stratified_subset, interactions = TRUE)

# Save SHAP importance (default plot) as PNG with 600 DPI
SHAP_XGB <- sv_importance(SHAP_viz_XGB, show_numbers = TRUE,max_display = 25) +
  ggtitle("SHAP XGB importance subtype") + theme_bw(base_size = 15)

SHAP_XGB$data <- SHAP_XGB$data |>
  mutate(ind = recode(ind,
                      "Class_1" = "B",
                      "Class_2" = "PreB",
                      "Class_3" = "PreT",
                      "Class_4" = "T"))
  

SHAP_XGB

ggsave(plot = SHAP_XGB,filename = "output/figures/SHAP_XGB_total.png", width = 12,height = 8,dpi = 600)

SHAP_XGB_list <- SHAP_XGB[["data"]] |>
  filter(ind == "B") |>
  select(feature) |>
  tibble()

SHAP_XGB

write_csv(x = SHAP_XGB,file = "output/tables/SHAP_XGB_list.csv")
```

## MLP

```{r}
set.seed(RANDOM_SEED)
library(baguette)

x <- train_data[-ncol(train_data)]
stratified_subset <- train_data %>%
  initial_split(prop = 100 / nrow(train_data), strata = Cell_type) %>%
  training() |>
  select(-Cell_type)

SHAP_kernel_NNET <- kernelshap(mlp_SHAP_fit, x, bg_X = stratified_subset,parallel = F,type = "prob")

# Step 2: Turn them into a shapviz object
SHAP_viz_NNET <- shapviz(SHAP_kernel_NNET, interactions = TRUE)

# Save SHAP importance (beeswarm plot) as PNG with 600 DPI and a title
plot_beeswarm <- sv_importance(SHAP_viz_NNET, show_numbers = TRUE, kind = "beeswarm") + theme_bw(base_size = 20)
plot_beeswarm
ggsave("SHAP/sv_importance_MLP_Subtype_beeswarm.png", plot = plot_beeswarm, dpi = 600,width = 12,height = 8)

# Save SHAP importance (default plot) as PNG with 600 DPI
plot_default <- sv_importance(SHAP_viz_NNET, show_numbers = TRUE) +
  ggtitle("SHAP Importance MLP Subtype") + theme_bw(base_size = 20)
plot_default
ggsave("SHAP/sv_importance_MLP_Subtype_default.png", plot = plot_default, dpi = 600,width = 12,height = 8)

# Save SHAP dependence plot for 'EBF1' as PNG with 600 DPI
plot_dependence <- sv_dependence(SHAP_viz_NNET, v = "EBF1", color_var = "auto") + theme_bw(base_size = 20)
plot_dependence
ggsave("SHAP/sv_dependence_MLP_Subtype_EBF1.png", plot = plot_dependence, dpi = 600,width = 12,height = 8)

# Save SHAP waterfall plot as PNG with 600 DPI
plot_waterfall <- sv_waterfall(SHAP_viz_NNET) + theme_bw(base_size = 20)
plot_waterfall
ggsave("SHAP/sv_waterfall_MLP_Subtype.png", plot = plot_waterfall, dpi = 600,width = 12,height = 8)


```


## STACK

```{r}
set.seed(RANDOM_SEED)
# Predict class labels from the stack
stack_preds_train <- predict(model_stack, new_data = train_data) %>%
  mutate(Cell_type_stack = .pred_class)

# Merge with original features
surrogate_data <- train_data %>%
  mutate(Cell_type_stack = stack_preds_train$Cell_type_stack) |>
  select(-Cell_type)

head(stack_preds_train)

library(xgboost)
library(vip)
library(shapviz)

library(xgboost)

# Design matrix
X <- data.matrix(surrogate_data[, -ncol(surrogate_data)])
y <- as.integer(surrogate_data$Cell_type_stack) - 1  # 0-indexed for XGB

dtrain <- xgb.DMatrix(data = X, label = y)


xgb_surrogate <- xgboost(
  data = dtrain,
  objective = "multi:softmax",
  num_class = length(levels(surrogate_data$Cell_type_stack)),
  nrounds = 2000,
  eta = 1,
  max_depth = 4,
  verbosity = 0,
  nthread = 10
)


# SHAP
sv <- shapviz(xgb_surrogate, X_pred = X, X = as.data.frame(X))

# Save SHAP importance (default plot) as PNG with 600 DPI
SHAP_STACK <- sv_importance(sv, show_numbers = TRUE,max_display = 25) +
  ggtitle("SHAP Stack importance subtype") + theme_bw(base_size = 15)

SHAP_STACK$data <- SHAP_STACK$data |>
  mutate(ind = recode(ind,
                      "Class_1" = "B",
                      "Class_2" = "PreB",
                      "Class_3" = "PreT",
                      "Class_4" = "T"))
  

SHAP_STACK

ggsave(plot = SHAP_STACK,filename = "output/figures/Total_SHAP_stack.png", width = 12,height = 8,dpi = 600)

SHAP_STACK_beeswarm <- sv_importance(sv, show_numbers = TRUE, kind = "beeswarm",) & theme_bw(base_size = 10)
labels <- c("B", "PreB", "PreT", "T")
SHAP_STACK_beeswarm[[1]]$labels$title <- "B"
SHAP_STACK_beeswarm[[2]]$labels$title <- "PreB"
SHAP_STACK_beeswarm[[3]]$labels$title <- "PreT"
SHAP_STACK_beeswarm[[4]]$labels$title <- "T"
# Now, `plot_beeswarm` should reflect the new titles per plot
print(SHAP_STACK_beeswarm)

ggsave(plot = SHAP_STACK_beeswarm,filename = "output/figures/SHAP_STACK_beeswarm.png", width = 12,height = 8,dpi = 600)

SHAP_STACK_list <- SHAP_STACK[["data"]] |>
  filter(ind == "B") |>
  select(feature) |>
  tibble()

SHAP_STACK_list

write_csv(x = SHAP_STACK_list, file = "output/tables/SHAP_STACK_list_25.csv")

# VIP
vip(xgb_surrogate, num_features = 20) + theme_bw(base_size = 12)

importance_matrix <- xgb.importance(model = xgb_surrogate )
xgb.ggplot.importance(importance_matrix = importance_matrix, top_n = 25, n_clusters = 3,rel_to_first = F) + 
  ggtitle("Feature Importance XGBoost HS Subtype Batch") +
  theme_bw(15)

```





# SHAP extraction

```{r BAR_plot}
plot_default_NNET <- sv_importance(SHAP_viz_NNET, show_numbers = TRUE,max_display = 30,color_bar_title = "Subtype") +
  ggtitle("SHAP Importance RF Subtype")
plot_default_NNET 

plot_default_RF <- sv_importance(SHAP_viz_RF, show_numbers = TRUE,max_display = 30,color_bar_title = "Subtype") +
  ggtitle("SHAP Importance RF Subtype")

plot_default_XGB <- sv_importance(SHAP_viz_XGB, show_numbers = TRUE,max_display = 30,color_bar_title = "Subtype") +
  ggtitle("SHAP Importance RF Subtype")
```

##  Extract the values

```{r  Extract the values}
# Define the function to process model data
process_model_data <- function(data, model_name, recode_kind = FALSE) {
  # If recoding 'kind' is needed
  if (recode_kind) {
    data <- data %>%
      mutate(ind = recode(ind,
                           "Class_1" = "B",
                           "Class_2" = "PreB",
                           "Class_3" = "PreT",
                           "Class_4" = "T"))
  }
  
  # Split the data based on 'ind' and rename 'feature' column with model name
  data %>%
      group_by(ind) %>%
      group_split() %>%
      setNames(unique(data$ind)) %>%
      map2(., names(.), ~ .x %>%
              select(feature) %>%
              rename(
                  !!paste0(model_name, "_", .y, "_feature") := feature#,
                  #!!paste0(model_name, "_", .y, "_values") := values
              ))
}

# Apply the function to NNET, RF, and XGB datasets

# NNET list - recode 'kind'
NNET_list <- process_model_data(tibble(plot_default_NNET$data) %>%
                                  mutate(ind = str_replace(ind, ".*_", "")), "NNET", recode_kind = F)

# RF list - no 'kind' recoding
RF_list <- process_model_data(tibble(plot_default_RF$data), "RF")

# XGB list - recode 'kind'
XGB_list <- process_model_data(tibble(plot_default_XGB$data), "XGB", recode_kind = TRUE)


```

## cbind the data 

```{r}

concatenate_model_data_by_index <- function(RF_list, NNET_list, XGB_list) {
  pmap(list(RF_list, NNET_list, XGB_list), cbind)
}

# Example usage
combined_data_list <- data.frame(concatenate_model_data_by_index(RF_list, NNET_list, XGB_list))

```

## Use RankAggreg with CE to obtain the best list with score 

```{r}
library(RankAggreg)
weights <- c(3,1,2,3,1,2,3,1,2,3,1,2)
#combined_data_list <- data.matrix(combined_data_list)

top25CE <- RankAggreg(x = t(combined_data_list),k = 25, seed=100, method="CE", maxIter=3000, convIn=10,verbose = F,importance = weights)
top25CE
plot(top25CE)
title(main = "Top 25 list",line = 2.7)

top25 <- tibble(top25 = top25CE$top.list)

# Convert Ensembl IDs to gene names
gene_names <- gconvert(query = top25$top25, organism = "hsapiens", 
         target = "ENSG", mthreshold = Inf, filter_na = TRUE)

gene_names <- gene_names %>% 
  distinct(input, .keep_all = TRUE)
top25 <- top25 %>%
  mutate( nnsembl = unique(gene_names$target) ) %>%
  mutate( description = unique(gene_names$description) )
write_csv(top25, "Top25_HS_Subtype_total.csv")



```


