collect_metrics(SVM_linear_res)
set.seed(RANDOM_SEED)
# Define the model specification with LASSO
lasso_spec <- multinom_reg(
penalty = tune(),      # Regularization parameter
mixture = 1          # 1 = LASSO, 0 = Ridge, values between = Elastic Net
) %>%
set_mode("classification") %>%
set_engine("glmnet")
# Use the Latin hypercube sampling approach for the penalty parameter
lasso_grid <- extract_parameter_set_dials(lasso_spec) %>%
#finalize(train_data) %>%  # Uncomment if needed for specific values
grid_space_filling(size = 20, type = "latin_hypercube")
# Create the workflow
lasso_workflow <-
workflow() %>%
add_recipe(recipe) %>%
add_model(lasso_spec) |>
add_case_weights(col = Weights)
# Perform initial grid tuning
tune_grid_results <- tune_grid(
lasso_workflow,
resamples = v_folds,
grid = lasso_grid,
metrics = class_metrics,
control = control_grid(save_pred = TRUE)
)
# Show initial results
initial_results <- show_best(tune_grid_results, metric = "mcc", n = 5)
print(initial_results)
# Further refinement with simulated annealing
tune_sa_results <- tune_sim_anneal(
lasso_workflow,
resamples = v_folds,
iter = 15,              # Number of simulated annealing iterations
initial = tune_grid_results,
metrics = class_metrics,
control = control_sim_anneal(no_improve = 10)
)
# Bayesian optimization tuning to refine the search
tune_bayes_results <- tune_bayes(
lasso_workflow,
resamples = v_folds,
iter = 15,              # Number of Bayesian iterations
initial = tune_sa_results,
metrics = class_metrics,
control = control_bayes(no_improve = 5, verbose_iter = T)
)
# Collect and display final tuning results
tuning_results <- show_best(tune_bayes_results, metric = "mcc", n = 10)
print(tuning_results)
# Create tuning visualization
autoplot(tune_bayes_results) +
theme_minimal() +
labs(title = "LASSO Model - Hyperparameter Tuning Results")
# Select the best hyperparameters
best_params <- select_best(tune_bayes_results, metric = "mcc")
print(best_params)
# Finalize the workflow with the best parameters
final_lasso_workflow <- finalize_workflow(lasso_workflow, best_params)
# Fit the model on training data
lasso_fit <- final_lasso_workflow %>%
fit(data = train_data)
# Print summary of the fitted workflow
print(lasso_fit)
# Save lighter model using butcher
cleaned_lasso <- butcher(lasso_fit, verbose = TRUE)
# Extract predictions from test data
predictions <- lasso_fit %>%
predict(new_data = test_data) %>%
mutate(type = test_data$type)
# Create a confusion matrix
confusion <- conf_mat(predictions, truth = type, estimate = .pred_class)
print(confusion)
# Get detailed metrics
metrics_df <- summary(confusion)
print(metrics_df)
# Visualize confusion matrix
autoplot(confusion, type = "heatmap") +
labs(title = "Confusion Matrix - LASSO Subtype Batch Heatmap")
# Save metrics to CSV
#write_csv(metrics_df, "LASSO_tuned_metrics.csv")
# Fit the model to resamples (this is what stacks needs)
LASSO_res <- fit_resamples(
final_lasso_workflow,
resamples = v_folds,
metrics = class_metrics,
control = control_resamples(save_pred = TRUE, save_workflow = TRUE)
)
# Now you can use this for stacking
# First, load the stacks library if not already loaded
set.seed(RANDOM_SEED)
library(stacks)
# Initialize a model stack
model_stack <- stacks() %>%
add_candidates(LASSO_res) %>%
add_candidates(knn_res) |>
add_candidates(SVM_linear_res) %>%
add_candidates(SVM_rbf_res) %>%
add_candidates(RF_res) %>%
add_candidates(XGB_res) %>%
blend_predictions(
metric = metric_set(mcc),
times = 200,                    # Increase for stability
control = control_grid(
verbose = TRUE,
save_pred = TRUE
)
) %>%
fit_members()
#saveRDS(object = model_stack,file = "model_stack.RDS")
# Visualize the model weights
autoplot(model_stack, type = "performance")
autoplot(model_stack, type = "weights")
autoplot(model_stack, type = "members")
# Now you can make predictions with the stack on new data
stack_preds <- model_stack %>%
predict(new_data = test_data) %>%
mutate(type = test_data$type)
# Evaluate stack performance
stack_confusion <- conf_mat(stack_preds, truth = type, estimate = .pred_class)
stack_metrics <- summary(stack_confusion)
stack_metrics
# Visualize confusion matrix for the stacked model
autoplot(stack_confusion, type = "heatmap") +
labs(title = "Confusion Matrix - Stacked Model for HS Subtype Classification")
# Save metrics
#write_csv(stack_metrics, "stacked_model_metrics.csv")
Cleaned_stack <- butcher(model_stack,verbose = T)
# Extract predictions from test data
predictions <- lasso_fit %>%
predict(new_data = test_data) %>%
mutate(type = test_data$type)
# Create a confusion matrix
confusion <- conf_mat(predictions, truth = type, estimate = .pred_class)
print(confusion)
# Get detailed metrics
metrics_df <- summary(confusion)
print(metrics_df)
# Visualize confusion matrix
autoplot(confusion, type = "heatmap") +
labs(title = "Confusion Matrix - LASSO Subtype Batch Heatmap")
# Save metrics to CSV
write_csv(metrics_df, "LASSO_tuned_metrics.csv")
# Fit the model to resamples (this is what stacks needs)
LASSO_res <- fit_resamples(
final_lasso_workflow,
resamples = v_folds,
metrics = class_metrics,
control = control_resamples(save_pred = TRUE, save_workflow = TRUE)
)
# Extract predictions from test data
predictions <- svm_linear_fit %>%
predict(new_data = test_data) %>%
mutate(type = test_data$type)
# Create a confusion matrix
confusion <- conf_mat(predictions, truth = type, estimate = .pred_class)
print(confusion)
# Get detailed metrics
metrics_df <- summary(confusion)
print(metrics_df)
# Visualize confusion matrix
autoplot(confusion, type = "heatmap") +
labs(title = "Confusion Matrix - SVM-Linear Subtype Batch Heatmap")
# Save metrics to CSV
write_csv(metrics_df, "output/tables/SVM_Linear_tuned_metrics.csv")
# Fit the model to resamples (this is what stacks needs)
SVM_linear_res <- fit_resamples(
final_svm_linear_workflow,
resamples = v_folds,
metrics = class_metrics,
control = control_resamples(save_pred = TRUE, save_workflow = TRUE)
)
collect_metrics(SVM_linear_res)
set.seed(RANDOM_SEED)
# Fit the model to resamples (this is what stacks needs)
SVM_rbf_res <- fit_resamples(
final_svm_rbf_workflow,
resamples = v_folds,
metrics = class_metrics,
control = control_resamples(save_pred = TRUE, save_workflow = TRUE)
)
collect_metrics(SVM_rbf_res)
# Extract predictions from test data
predictions <- svm_rbf_fit %>%
predict(new_data = test_data) %>%
mutate(type = test_data$type)
# Create a confusion matrix
confusion <- conf_mat(predictions, truth = type, estimate = .pred_class)
print(confusion)
# Get detailed metrics
metrics_df <- summary(confusion)
print(metrics_df)
# Visualize confusion matrix
autoplot(confusion, type = "heatmap") +
#theme_void() +
labs(title = "Confusion Matrix - SVM-RBF Subtype Batch Heatmap")
# Save metrics to CSV
write_csv(metrics_df, "output/tables/SVM_RBF_tuned_metrics.csv")
set.seed
# Fit the model to resamples (this is what stacks needs)
XGB_res <- fit_resamples(
xgb_final_workflow,
resamples = v_folds,
metrics = class_metrics,
control = control_resamples(save_pred = TRUE, save_workflow = TRUE)
)
collect_metrics(XGB_res)
# Extract predictions
predictions <- xgb_fit %>%
predict(new_data = test_data) %>%
mutate(type = test_data$type)
# Create a confusion matrix
confusion <- conf_mat(predictions,truth = type, estimate = .pred_class)
metrics_df <- summary(confusion)
metrics_df
# Visualize confusion matrix as a heatmap
autoplot(confusion, type = "heatmap") +
labs(title = "Confusion Matrix - XGB HS Subtype Batch Heatmap")
write_csv(metrics_df,"output/tables/XGB_tuned_metrics.csv")
set.seed(RANDOM_SEED)
knn_res <- fit_resamples(
final_knn_workflow,
resamples = v_folds,
metrics = class_metrics,
control = control_resamples(save_pred = TRUE, save_workflow = TRUE)
)
collect_metrics(knn_res)
# Extract predictions
predictions <- knn_fit %>%
predict(new_data = test_data) %>%
mutate(type = test_data$type)
# Create a confusion matrix
confusion <- conf_mat(predictions,truth = type, estimate = .pred_class)
metrics_df <- summary(confusion)
metrics_df
# View the confusion matrix
autoplot(confusion, type = "heatmap") +
labs(title = "Confusion Matrix - KNN(8) HS Subtype Batch Heatmap ")
write_csv(metrics_df, "output/tables/KNN_tuned_metrics.csv")
# Set seed for reproducibility
set.seed(RANDOM_SEED)
# Fit the model to resamples (this is what stacks needs)
RF_res <- fit_resamples(
final_rf_workflow,
resamples = v_folds,
metrics = class_metrics,
control = control_resamples(save_pred = TRUE, save_workflow = TRUE)
)
collect_metrics(RF_res)
# Extract predictions from the trained random forest model
predictions <- rf_fit %>%
predict(new_data = test_data) %>% # Generate predictions on the test data
dplyr::mutate(type = test_data$type) # Add true cell type to predictions
# Create a confusion matrix to evaluate model performance
confusion <- conf_mat(predictions, truth = type, estimate = .pred_class)
metrics_df <- summary(confusion) # Summarize confusion matrix metrics
metrics_df # Display metrics
# Visualize confusion matrix as a heatmap
autoplot(confusion, type = "heatmap") +
labs(title = "Confusion Matrix - RF HS Subtype Batch Heatmap")
write_csv(metrics_df, "output/tables/RF_tuned_metrics.csv")
# Visualize the model weights
autoplot(model_stack, type = "performance")
autoplot(model_stack, type = "weights")
autoplot(model_stack, type = "members")
# Now you can make predictions with the stack on new data
stack_preds <- model_stack %>%
predict(new_data = test_data) %>%
mutate(type = test_data$type)
# Evaluate stack performance
stack_confusion <- conf_mat(stack_preds, truth = type, estimate = .pred_class)
stack_metrics <- summary(stack_confusion)
stack_metrics
# Visualize confusion matrix for the stacked model
autoplot(stack_confusion, type = "heatmap") +
labs(title = "Confusion Matrix - Stacked Model for HS Subtype Classification")
# Save metrics
write_csv(stack_metrics, "output/tables/stacked_model_metrics.csv")
View(knn_param_space)
set.seed(RANDOM_SEED)
# Define KNN model spec with tuneable neighbors only
knn_spec <- nearest_neighbor(
weight_func = "optimal",
neighbors = tune()
) %>%
set_mode("classification") %>%
set_engine("kknn") |>
translate()
# Extract parameter space and finalize for train_data
knn_param_space <- extract_parameter_set_dials(knn_spec) %>%
finalize(train_data) |>
update(neighbors = neighbors(c(2L,89L)) )
# Generate a smaller, efficient Latin hypercube grid for tuning
knn_grid <- grid_space_filling(knn_param_space, size = 25, type = "latin_hypercube")
# Build the workflow
knn_workflow <- workflow() %>%
add_recipe(recipe) %>%
add_model(knn_spec)
# Step 1: Tune with grid search
knn_tune_grid <- tune_grid(
knn_workflow,
resamples = v_folds,
grid = knn_grid,
metrics = class_metrics,
control = control_grid(save_pred = TRUE)
)
# Show top tuning results by MCC
best_knn_results <- show_best(knn_tune_grid, metric = "mcc")
print(best_knn_results)
# Select best hyperparameters
best_knn_params <- select_best(knn_tune_grid, metric = "mcc")
# Finalize workflow with best params and fit on full training data
final_knn_workflow <- finalize_workflow(knn_workflow, best_knn_params)
knn_fit <- fit(final_knn_workflow, data = train_data)
print(knn_fit)
# Save lighter model
#cleaned_KNN <- butcher(Knn_fit, verbose = TRUE)
set.seed(RANDOM_SEED)
knn_res <- fit_resamples(
final_knn_workflow,
resamples = v_folds,
metrics = class_metrics,
control = control_resamples(save_pred = TRUE, save_workflow = TRUE)
)
collect_metrics(knn_res)
# Extract predictions
predictions <- knn_fit %>%
predict(new_data = test_data) %>%
mutate(type = test_data$type)
# Create a confusion matrix
confusion <- conf_mat(predictions,truth = type, estimate = .pred_class)
metrics_df <- summary(confusion)
metrics_df
# View the confusion matrix
autoplot(confusion, type = "heatmap") +
labs(title = "Confusion Matrix - KNN(8) HS Subtype Batch Heatmap ")
write_csv(metrics_df, "output/tables/KNN_tuned_metrics.csv")
# Now you can use this for stacking
# First, load the stacks library if not already loaded
set.seed(RANDOM_SEED)
library(stacks)
# Initialize a model stack
model_stack <- stacks() %>%
add_candidates(LASSO_res) %>%
add_candidates(knn_res) |>
add_candidates(SVM_linear_res) %>%
add_candidates(SVM_rbf_res) %>%
add_candidates(RF_res) %>%
add_candidates(XGB_res) %>%
blend_predictions(
metric = metric_set(mcc),
times = 200,                    # Increase for stability
control = control_grid(
verbose = TRUE,
save_pred = TRUE
)
) %>%
fit_members()
#saveRDS(object = model_stack,file = "model_stack.RDS")
# Visualize the model weights
autoplot(model_stack, type = "performance")
autoplot(model_stack, type = "weights")
autoplot(model_stack, type = "members")
# Now you can make predictions with the stack on new data
stack_preds <- model_stack %>%
predict(new_data = test_data) %>%
mutate(type = test_data$type)
# Evaluate stack performance
stack_confusion <- conf_mat(stack_preds, truth = type, estimate = .pred_class)
stack_metrics <- summary(stack_confusion)
stack_metrics
# Visualize confusion matrix for the stacked model
autoplot(stack_confusion, type = "heatmap") +
labs(title = "Confusion Matrix - Stacked Model for HS Subtype Classification")
# Save metrics
write_csv(stack_metrics, "output/tables/stacked_model_metrics.csv")
Cleaned_stack <- butcher(model_stack,verbose = T)
library(tidyverse)
# Define a function to process metrics files
process_metrics <- function(file, model_name) {
read_csv(file) %>%
select(-.estimator) %>%
t() %>%
as.data.frame() %>%
`rownames<-`(NULL) %>%
setNames(.[1, ]) %>%
slice(-1) %>%
mutate(Model = model_name) %>%
as_tibble()
}
# List of all metrics files and their corresponding model names
metrics_files <- list(
"output/tables/RF_tuned_metrics.csv" = "RF",
#"output/tables/Mlp_tuned_metrics.csv" = "MLP",
"output/tables/KNN_tuned_metrics.csv" = "KNN(8)",
"output/tables/XGB_tuned_metrics.csv" = "XGBoost",
"output/tables/SVM_RBF_tuned_metrics.csv" = "SVM RBF",
"output/tables/SVM_Linear_tuned_metrics.csv" = "SVM Linear",
"output/tables/LASSO_tuned_metrics.csv" = "LASSO",
"output/tables/stacked_model_metrics.csv" = "STACKED (all models)"
)
# Process all files and combine
all_metrics <- map2_dfr(names(metrics_files), metrics_files, process_metrics) %>%
mutate(across(c(bal_accuracy, kap, f_meas, mcc), as.numeric)) %>%
select(-ppv) |>
mutate(UN_mcc = (mcc + 1) / 2) |>
select(Model, mcc, everything()) %>%
arrange(desc(mcc)) %>%
mutate(across(where(is.numeric), ~ signif(.x, 3)))
all_metrics
# Save results
write_csv(all_metrics, "Metrics_woHS_AGE.csv")
library(ggsci)
library(dplyr)
library(tidyr)
library(ggplot2)
# Your data wrangling
plot_data <- all_metrics %>%
select(Model, f_meas, mcc, bal_accuracy) %>%
mutate(Model = reorder(Model, mcc)) %>%  # Order by MCC
pivot_longer(cols = c(f_meas, mcc, bal_accuracy),
names_to = "Metric", values_to = "Value") %>%
mutate(Label = sprintf("%.2f", Value)) %>%
mutate(Metric = recode(Metric,
"f_meas" = "F1 Score",
"mcc" = "Matthews Correlation Coefficient",
"bal_accuracy" = "Balanced Accuracy"))
# Plot
HS_simple_bar <- ggplot(plot_data, aes(x = Model, y = Value, fill = Metric)) +
geom_col(position = position_dodge(0.7), width = 0.6) +
geom_text(aes(label = Label), position = position_dodge(0.7), vjust = -0.5, size = 4.5) +
scale_fill_npg() +
labs(title = "woHS Age Models Performances",
y = "Score",
fill = "Metric") +
theme_bw(base_size = 15) +
theme(plot.title = element_text(hjust = 0.5, face = "bold"),
legend.position = "top") +
scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.2))
print(HS_simple_bar)
ggsave("output/figures/woHS_simple_bar_AGE.png", plot = HS_simple_bar, width = 12, height = 8, dpi = 600, bg = "white")
library(xgboost)
library(kernelshap)
library(shapviz)
# Extract fitted xgboost model
XGB <- extract_fit_engine(xgb_fit)
# Prepare predictor matrix (same as used in model fitting)
x <- baked_data
x$type <- as.numeric(x$type) - 1
# pediatric = 1, adult = 0
SHAP_viz_XGB <- shapviz(XGB, X_pred = X_pred, X = x %>% select(-c("type","Weights")), interactions = TRUE)
# Save SHAP importance (default plot) as PNG with 600 DPI
SHAP_XGB <- sv_importance(SHAP_viz_XGB, show_numbers = TRUE,max_display = 25) +
ggtitle("SHAP XGB importance woHS Age") + theme_bw(base_size = 15)
SHAP_XGB
ggsave(plot = SHAP_XGB,filename = "output/figures/SHAP_XGB_total.png", width = 12,height = 8,dpi = 600)
SHAP_XGB_list <- SHAP_XGB[["data"]] |>
tibble()
SHAP_XGB_list
write_csv(x = SHAP_XGB_list,file = "output/tables/SHAP_XGB_woHS_Age.csv")
library(xgboost)
library(kernelshap)
library(shapviz)
# Extract fitted xgboost model
XGB <- extract_fit_engine(xgb_fit)
# Prepare predictor matrix (should match training predictors)
x <- baked_data
x$type <- as.numeric(x$type) - 1  # assuming binary outcome for SHAP
X_pred <- x %>% select(-c("type", "Weights"))  # this is what shapviz expects
# Compute SHAP values with interaction effects
SHAP_viz_XGB <- shapviz(XGB, X_pred = X_pred, X = X_pred, interactions = TRUE)
library(xgboost)
library(kernelshap)
library(shapviz)
# Extract fitted xgboost model
XGB <- extract_fit_engine(xgb_fit)
# Prepare predictor matrix (should match training predictors)
x <- baked_data
x$type <- as.numeric(x$type) - 1  # assuming binary outcome for SHAP
X_pred <- as.matrix(x %>% select(-c("type", "Weights")))  # this is what shapviz expects
# Compute SHAP values with interaction effects
SHAP_viz_XGB <- shapviz(XGB, X_pred = X_pred, X = X_pred, interactions = TRUE)
# Save SHAP importance (default plot) as PNG with 600 DPI
SHAP_XGB <- sv_importance(SHAP_viz_XGB, show_numbers = TRUE,max_display = 25) +
ggtitle("SHAP XGB importance woHS Age") + theme_bw(base_size = 15)
SHAP_XGB
ggsave(plot = SHAP_XGB,filename = "output/figures/SHAP_XGB_total.png", width = 12,height = 8,dpi = 600)
SHAP_XGB_list <- SHAP_XGB[["data"]] |>
tibble()
SHAP_XGB_list
write_csv(x = SHAP_XGB_list,file = "output/tables/SHAP_XGB_woHS_Age.csv")
library(ggplot2)
library(ggrepel)  # For non-overlapping text labels
# Select only the columns we need
plot_data_scatter <- all_metrics %>%
select(Model, f_meas, UN_mcc)
# Create the scatter plot
HS_scatter <- ggplot(plot_data_scatter, aes(x = f_meas, y = UN_mcc, color = Model)) +
geom_point(size = 4) +
scale_color_npg() +  # from ggsci
geom_text_repel(aes(label = Model), size = 4, seed = 1234,nudge_x = -0.03 ) +  # Labels next to dots
labs(title = "F1 Score vs. Matthews Correlation Coefficient (UN) woHS Age",
x = "F1 Score",
y = "MCC (UN)") +
theme_bw(base_size = 14) +
theme(plot.title = element_text(hjust = 0.5, face = "bold"),
legend.position = "none")
# Show plot
print(HS_scatter)
# Optional: Save to file
ggsave("output/figures/woHS_scatter_F1_vs_MCC.png", plot = HS_scatter, width = 10, height = 8, dpi = 600, bg = "white")
